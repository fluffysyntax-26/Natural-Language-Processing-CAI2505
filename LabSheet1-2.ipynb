{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62f7cf9d-b245-45b5-8189-5fb91bd24b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36dd94d9-3fb2-469c-ab23-b6463979f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Natural Language Processing is fascinating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fef07a37-00ba-48dc-93a7-25f70c543603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural (96,)\n",
      "Language (96,)\n",
      "Processing (96,)\n",
      "is (96,)\n",
      "fascinating (96,)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for token in doc: \n",
    "    print(token.text, token.vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fd0db8a-8f89-4022-a608-cbf1199c30b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['machine', 'learning', 'is', 'fun', '.'],\n",
       " ['natural', 'language', 'processing', '.'],\n",
       " ['deep', 'learning', 'models']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "corpus = \"Machine Learning is fun. natural language processing. deep learning models\"\n",
    "sents = [[w.lower() for w in nltk.word_tokenize(s)] for s in nltk.sent_tokenize(corpus)]\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77321c8a-967c-4153-9593-4681969c8698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'natural':  [-0.01648536  0.01859871 -0.00039532 -0.00393455  0.00920726 -0.00819063\n",
      "  0.00548623  0.01387993  0.01213085 -0.01502159  0.0187647   0.00934362\n",
      "  0.00793224 -0.01248701  0.01691996 -0.00430033  0.01765038 -0.01072401\n",
      " -0.01625884  0.01364912  0.00334239 -0.00439702  0.0190272   0.01898771\n",
      " -0.01954809  0.00501046  0.01231338  0.00774491  0.00404557  0.000861\n",
      "  0.00134726 -0.00764127 -0.0142805  -0.00417774  0.0078478   0.01763737\n",
      "  0.0185183  -0.01195187 -0.01880534  0.01952875  0.00685957  0.01033223\n",
      "  0.01256469 -0.00560853  0.01464541  0.00566054  0.00574201 -0.00476074\n",
      " -0.0062565  -0.00474028]\n"
     ]
    }
   ],
   "source": [
    "# convert word to vec\n",
    "model = Word2Vec(sents, vector_size=50, window=3, min_count=1)\n",
    "vector = model.wv['natural']\n",
    "print(\"Vector for 'natural': \", vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfb46380-d1e1-484a-8d2e-e717785338a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:  0.22442302\n"
     ]
    }
   ],
   "source": [
    "# Word Similarity using word2vec\n",
    "similarity = model.wv.similarity(\"machine\", \"language\")\n",
    "print(\"Similarity: \", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7eac76dc-7d76-48a1-b018-492a237ac3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.079084 -0.81504   1.7901    0.91653   0.10797  -0.55628  -0.84427\n",
      " -1.4951    0.13418   0.63627   0.35146   0.25813  -0.55029   0.51056\n",
      "  0.37409   0.12092  -1.6166    0.83653   0.14202  -0.52348   0.73453\n",
      "  0.12207  -0.49079   0.32533   0.45306  -1.585    -0.63848  -1.0053\n",
      "  0.10454  -0.42984   3.181    -0.62187   0.16819  -1.0139    0.064058\n",
      "  0.57844  -0.4556    0.73783   0.37203  -0.57722   0.66441   0.055129\n",
      "  0.037891  1.3275    0.30991   0.50697   1.2357    0.1274   -0.11434\n",
      "  0.20709 ]\n",
      "0.77411586\n"
     ]
    }
   ],
   "source": [
    "# GloVe Embeddings (Pre-trained)\n",
    "import gensim.downloader as api\n",
    "glove = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "print(glove['computer'])\n",
    "print(glove.similarity(\"computer\", \"laptop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a232924-b6bc-42db-8adf-25656d355bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contextual Embedding using BERT\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deb4fde0-7d11-4a9d-9c03-9f224411563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sentence = \"The bank is near the river\"\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "outputs = model(**inputs)\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d243423f-e31e-41da-a8cc-27ae21be4a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0362,  0.0981, -0.0198,  ..., -0.0685, -0.0597, -0.0195],\n",
      "         [ 0.1371,  0.0440, -0.0555,  ..., -0.2686,  0.0399,  0.1294],\n",
      "         [ 0.0159,  0.0557,  0.0038,  ..., -0.0188, -0.1045, -0.0836],\n",
      "         [ 0.1222,  0.2120,  0.0749,  ...,  0.0946,  0.0471, -0.0361],\n",
      "         [ 0.0351, -0.0155,  0.0312,  ..., -0.0737,  0.0225,  0.0391],\n",
      "         [-0.0304,  0.1093, -0.0470,  ..., -0.1169, -0.0684, -0.0506]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>) tensor([[[-0.0362,  0.0981, -0.0198,  ..., -0.0685, -0.0597, -0.0195],\n",
      "         [ 0.1371,  0.0440, -0.0555,  ..., -0.2686,  0.0399,  0.1294],\n",
      "         [ 0.0159,  0.0557,  0.0038,  ..., -0.0188, -0.1045, -0.0836],\n",
      "         [ 0.1222,  0.2120,  0.0749,  ...,  0.0946,  0.0471, -0.0361],\n",
      "         [ 0.0351, -0.0155,  0.0312,  ..., -0.0737,  0.0225,  0.0391],\n",
      "         [-0.0304,  0.1093, -0.0470,  ..., -0.1169, -0.0684, -0.0506]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# context change Example\n",
    "sent1 = \"I deposited money in the bank\"\n",
    "sent2 = \"The river bank is beautiful\"\n",
    "\n",
    "inputs1 = tokenizer(sent1, return_tensors='pt')\n",
    "inputs2 = tokenizer(sent2, return_tensors='pt')\n",
    "\n",
    "emb1 = model(**inputs).last_hidden_state\n",
    "emb2 = model(**inputs).last_hidden_state\n",
    "\n",
    "print(emb1, emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d7703ff-91ce-4da2-8110-819e27d76bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714343bcbd6439a9550c53a07fbbddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dell\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60def70f823b46ee934a83f51fbcd604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc35891b9da347149a9f7e43e1e6eb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b779cee5da74df9ba4d12ec4fffa197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d6e78a054b45a1893c74cd79e73868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f01bc230cd47a982f01c561776af3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "# RoBERTa embedding: \n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Word representations are powerful\", return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b32b1-5a3c-4185-b524-804f97b504dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
